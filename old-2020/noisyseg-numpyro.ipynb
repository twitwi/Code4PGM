{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp, random, ops, lax\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tools import obj_dic, show_heatmap_contours\n",
    "\n",
    "import numpyro\n",
    "from numpyro import distributions as dist, sample, plate, param\n",
    "from numpyro.infer import autoguide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpyro.__version__)\n",
    "#numpyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_K = 1412\n",
    "\n",
    "def gen_data(r, N):\n",
    "    rk = random.split(r, 4)\n",
    "    a = random.normal(rk[0], (1,2))*30\n",
    "    b = random.normal(rk[1], (1,2))*30\n",
    "    u = random.uniform(rk[2], (N,1))\n",
    "    p = a + (b-a) * u + random.normal(rk[3], (N, 2))\n",
    "    return p, obj_dic(locals())\n",
    "\n",
    "data, gt = gen_data(random.PRNGKey(TRAIN_K), 1000)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], marker='.', alpha=0.1)\n",
    "plt.scatter(gt.a[0,0], gt.a[0,1], marker='+')\n",
    "plt.scatter(gt.b[0,0], gt.b[0,1], marker='+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_contours():\n",
    "    data, gt = gen_data(random.PRNGKey(TRAIN_K), 50000)\n",
    "    show_heatmap_contours(data[:,0], data[:,1], bins=100)\n",
    "    plt.scatter(gt.a[0,0], gt.a[0,1], marker='+')\n",
    "    plt.scatter(gt.b[0,0], gt.b[0,1], marker='+')\n",
    "    \n",
    "true_contours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = (data.shape[0]*1) # // 10 # for minibatching (that does not work properly...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative model/story, used (as p(x|θ)) for variational inference and for MCMC\n",
    "def model(data, sub=SUB, with_obs=True):\n",
    "    N = data.shape[0]\n",
    "    a = sample('a', dist.MultivariateNormal(jnp.zeros((2,)), jnp.eye(2)*100**2))\n",
    "    b = sample('b', dist.MultivariateNormal(jnp.zeros((2,)), jnp.eye(2)*100**2))\n",
    "\n",
    "    with plate('data', N, subsample_size=sub) as ind:\n",
    "        u = sample('u', dist.Uniform(0, 1))\n",
    "        obs = sample('obs', dist.MultivariateNormal(a + (b-a)*u[:,None], jnp.eye(2)), obs=data[ind,:] if with_obs else None)\n",
    "        return obs\n",
    "\n",
    "    \n",
    "# This guide function is the variational distribution (definition of the approximating q(θ))\n",
    "def guide(data):\n",
    "    N = data.shape[0]\n",
    "    # not so bad init\n",
    "    aμinit = jnp.min(data, 0)\n",
    "    bμinit = jnp.max(data, 0)\n",
    "    med = jnp.median(data, 0)\n",
    "    aμinit = aμinit + random.uniform(random.PRNGKey(201), shape=(2,)) * (med - aμinit)\n",
    "    bμinit = bμinit + random.uniform(random.PRNGKey(202), shape=(2,)) * (med - bμinit)\n",
    "\n",
    "    aμ = param('qaμ', aμinit)\n",
    "    aσ = param('qaσ', 0.1, constraint=dist.constraints.positive)\n",
    "    bμ = param('qbμ', bμinit)\n",
    "    bσ = param('qbσ', 0.1, constraint=dist.constraints.positive)\n",
    "    a = sample('a', dist.MultivariateNormal(aμ, jnp.eye(2)*aσ))\n",
    "    b = sample('b', dist.MultivariateNormal(bμ, jnp.eye(2)*bσ))\n",
    "\n",
    "    uα = param('uα', jnp.zeros(N)+1, constraint=dist.constraints.positive)\n",
    "    uβ = param('uβ', jnp.zeros(N)+1, constraint=dist.constraints.positive)\n",
    "    #uμ = param('uμ', jnp.ones(N)*0.5, constraint=dist.constraints.interval(0, 1))\n",
    "    #uσ = param('uσ', jnp.ones(N)*0.1, constraint=dist.constraints.positive)\n",
    "\n",
    "#    for i in range(N):\n",
    "#        u = pyro.sample('u_{}'.format(i), dist.Beta(1+uα[i], 1+uβ[i]))\n",
    "\n",
    "#    for i in pyro.plate('data', N):\n",
    "#        u = pyro.sample('u_{}'.format(i), dist.Beta(1+uα[i], 1+uβ[i]))\n",
    "\n",
    "    with plate('data', N, subsample_size=SUB) as ind:\n",
    "        u = sample('u', dist.Beta(1+uα[ind], 1+uβ[ind]))\n",
    "        #uu = sample('uu', dist.Normal(uμ[ind], uσ[ind]), infer={'is_auxiliary': True})\n",
    "        #u = sample('u', dist.Delta(uu)) #dist.Delta(jnp.clamp(uu, 0, 1)))\n",
    "\n",
    "history = []\n",
    "\n",
    "\n",
    "##### alternative configuration\n",
    "auto_guide = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "\n",
    "if auto_guide:\n",
    "    lr = 0.05\n",
    "    guide = autoguide.AutoDiagonalNormal(model)\n",
    "    #guide =  autoguide.AutoLowRankMultivariateNormal(model, rank=20)\n",
    "    #elbo = autoguide.AutoContinuousELBO()\n",
    "    elbo = numpyro.infer.Trace_ELBO()#num_particles=1, max_plate_nesting=1)\n",
    "else:\n",
    "    elbo = numpyro.infer.Trace_ELBO()#num_particles=1, max_plate_nesting=1)\n",
    "\n",
    "optimizer = numpyro.optim.Adam(step_size=lr)#{'lr': lr, 'betas': [0.9, 0.99]})\n",
    "\n",
    "svi = numpyro.infer.SVI(model, guide, optimizer, loss=elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### %%time\n",
    "\n",
    "n_steps = 2000\n",
    "init_state = svi.init(random.PRNGKey(42000), data)\n",
    "\n",
    "#print(init_state)\n",
    "\n",
    "def scanner(pstate, i):\n",
    "    state, loss = svi.update(pstate, data)\n",
    "    return state, (loss, svi.get_params(state))\n",
    "\n",
    "state, (losses, params) = lax.scan(scanner, init_state, jnp.arange(n_steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "print(losses[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if auto_guide:\n",
    "    print(params['auto_loc'].shape)\n",
    "else:\n",
    "    print(params['qaμ'].shape)\n",
    "    print(jnp.hstack([params['qaμ'], params['qbμ']]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "if auto_guide:\n",
    "    history = params['auto_loc'][:,:4]\n",
    "else:\n",
    "    history = numpy.hstack([params['qaμ'], params['qbμ']])\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], marker='.', alpha=0.1)\n",
    "plt.scatter(gt.a[0,0], gt.a[0,1], marker='+')\n",
    "plt.scatter(gt.b[0,0], gt.b[0,1], marker='+')\n",
    "\n",
    "h = numpy.array(history[-2000:])\n",
    "print(h.shape)\n",
    "plt.plot(h[:,0], h[:,1], label='Mean a accross iterations')\n",
    "plt.plot(h[:,2], h[:,3], label='Mean b accross iterations')\n",
    "plt.scatter(h[-1,0], h[-1,1])\n",
    "plt.scatter(h[-1,2], h[-1,3])\n",
    "plt.plot([h[-1,0], h[-1,2]], [h[-1,1], h[-1,3]], '--', label=\"Final a--b\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_posterior_predictive = False\n",
    "\n",
    "if plot_posterior_predictive:\n",
    "    \n",
    "    pred = numpyro.handlers.seed(model, random.PRNGKey(4242))\n",
    "    pred = numpyro.handlers.condition(pred,\n",
    "                                      dict(\n",
    "                                          a=jnp.array([h[-1,0], h[-1,1]]),\n",
    "                                          b=jnp.array([h[-1,2], h[-1,3]])))\n",
    "    \n",
    "    N = 50000\n",
    "    samples = pred(jnp.zeros((N,2)), sub=N, with_obs=False)\n",
    "    print(samples.shape)\n",
    "    plt.scatter(data[:,0], data[:,1], marker='.', alpha=0.1)\n",
    "    show_heatmap_contours(samples[:,0], samples[:,1], bins=100)\n",
    "    plt.plot([h[-1,0], h[-1,2]], [h[-1,1], h[-1,3]], 'r--', label=\"Final a--b\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: you can go back above and enable/disable the auto-guide and retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer.mcmc import MCMC\n",
    "from numpyro.infer.hmc import NUTS, HMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmodel = HMC(model)\n",
    "mcmc = MCMC(mcmodel, num_warmup=500, num_samples=1000, num_chains=10)\n",
    "mcmc.run(random.PRNGKey(42043), data)\n",
    "#mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a and b can be equivalently swapped, the MCMC sampler generates 'a' samples at both configurations\n",
    "plt.scatter(mcmc.get_samples()['a'][:,0], mcmc.get_samples()['a'][:,1])\n",
    "plt.xlabel('$a_x$')\n",
    "plt.ylabel('$a_y$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if 'a' and 'b' are always coherent\n",
    "plt.scatter(mcmc.get_samples()['a'][:,0], mcmc.get_samples()['b'][:,0])\n",
    "plt.xlabel('$a_x$')\n",
    "plt.ylabel('$b_x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "for i in range(100):\n",
    "    u = mcmc.get_samples()['u']\n",
    "    subu = u[-100:,i]\n",
    "    plt.scatter(subu, u[-1,i]+numpy.random.uniform(0, 1, subu.shape)/10000, marker='.', alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
