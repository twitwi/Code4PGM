{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lda.datasets as dataset_loader # for loading a test dataset\n",
    "import lda as lda_lib\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import digamma\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm import tqdm\n",
    "\n",
    "md = lambda *args: display(Markdown(*args))\n",
    "\n",
    "def flatten(L): return [e for l in L for e in l]\n",
    "def draw_cat_prop(p): return np.random.choice(p.shape[0], p = p/np.sum(p))\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395, 4258) (395,) (4258,)\n"
     ]
    }
   ],
   "source": [
    "d_to_text = dataset_loader.load_reuters_titles()\n",
    "v_to_text = dataset_loader.load_reuters_vocab()\n",
    "nW = dataset_loader.load_reuters()\n",
    "\n",
    "print(nW.shape, np.shape(d_to_text), np.shape(v_to_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = nW.shape[0] # set D to a smaller constant (below) to test with less documents\n",
    "n_topics = 10\n",
    "V = nW.shape[1]\n",
    "\n",
    "D,n_topics = 10, 4 # smaller setup\n",
    "\n",
    "def _line_to_list_of_words(l):\n",
    "    return flatten(([v]*l[v] for v in range(len(l))))\n",
    "w = [_line_to_list_of_words(nW[d,:]) for d in range(D)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Gibbs sampler (very basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "... initializing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "... running gibbs sampler"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:07<00:00, 14.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "We obtained the following topics:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: buckingham / largest / prince / reforms / committee / photo / made / american / baroque / confirmed / open / spared / family / comedy / hit / spokeswoman / reign / cost / radical / visiting"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: 1945 / tomorrow / white / religions / became / pair / raised / 2000 / wait / deaths / considered / several / taken / fitted / project / 1977 / gay / historic / settlement / feature"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: charles / royal / diana / divorce / take / queen / church / camilla / monday / british / intention / public / becomes / year / britain / 25 / interview / palace / dresden / denied"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: mother / teresa / sen / sister / heart / told / calcutta / home / doctors / saint / living / charity / missionaries / fever / respirator / dr / condition / 100 / earlier / birthday"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lda_gibbs(K=42, LOOPS=112, α=5., β=.1):\n",
    "    if type(α) == type(1.):\n",
    "        α = np.ones(K)*α\n",
    "    if type(β) == type(1.):\n",
    "        β = np.ones(V)*β\n",
    "        \n",
    "    α0 = np.sum(α)\n",
    "    β0 = np.sum(β)\n",
    "    \n",
    "    md('... initializing')\n",
    "    # initialize sampled variables\n",
    "    z = [np.random.choice(K, len(w[d])) for d in range(D)]\n",
    "    φ = np.zeros((K, V)) # we'll draw right away from the counts\n",
    "    θ = np.zeros((D, K)) # we'll draw right away from the counts\n",
    "    # initialize count tables\n",
    "    c_dk = np.zeros((D, K))\n",
    "    for d in range(D):\n",
    "        c_dk[d,:] = np.bincount(z[d], minlength=K)\n",
    "    c_kv = np.zeros((K, V))\n",
    "    for d in range(D):\n",
    "        for i in range(len(w[d])):\n",
    "            c_kv[z[d][i], w[d][i]] += 1\n",
    "    #print(np.sum(c_dk), np.sum(c_kv))\n",
    "    \n",
    "    md('... running gibbs sampler')\n",
    "    for loop in tqdm(range(LOOPS)):\n",
    "        for d in range(D):\n",
    "            θ[d,:] = np.random.dirichlet(α[:] + c_dk[d,:])\n",
    "        for k in range(K):\n",
    "            φ[k,:] = np.random.dirichlet(β[:] + c_kv[k,:])\n",
    "        for d in range(D):\n",
    "            for i in range(len(w[d])):\n",
    "                _wdi = w[d][i]\n",
    "                _zdi = z[d][i]\n",
    "                c_dk[d, _zdi] -= 1\n",
    "                c_kv[_zdi, _wdi] -= 1\n",
    "                z[d][i] = draw_cat_prop(φ[:,_wdi]*θ[d,:])\n",
    "                _zdi = z[d][i]\n",
    "                c_dk[d, _zdi] += 1\n",
    "                c_kv[_zdi, _wdi] += 1\n",
    "    \n",
    "    md('We obtained the following topics:')\n",
    "    #plt.imshow(φ)\n",
    "    #plt.show()\n",
    "    for k in range(K):\n",
    "        txt = 'Topic '+str(k)+': '\n",
    "        words = np.argsort(φ[k,:])[::-1]\n",
    "        txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "        md(txt)\n",
    "    \n",
    "    \n",
    "lda_gibbs(n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Simple Gibbs sampler [timing: 04:46.00]\n",
    "\n",
    "> Topic 0: political / minister / last / government / leader / president / party / former / church / million / michael / first / visit / years / romania / nation / support / country / christian / return\n",
    "\n",
    "> Topic 1: charles / prince / family / church / public / royal / parker / british / diana / king / bowles / queen / marriage / years / britain / camilla / newspaper / throne / princess / couple\n",
    "\n",
    "> Topic 2: pope / vatican / church / surgery / john / roman / paul / mass / trip / pontiff / world / hospital / rome / sunday / during / operation / poland / year / since / told\n",
    "\n",
    "> Topic 3: u.s / harriman / france / clinton / paris / churchill / american / british / ambassador / died / first / late / film / president / winston / became / close / pamela / war / french\n",
    "\n",
    "> Topic 4: people / years / world / church / war / ceremony / long / place / country / great / took / union / state / first / very / buried / south / several / communist / town\n",
    "\n",
    "> Topic 5: yeltsin / president / russian / police / miami / kremlin / operation / power / say / russia / cunanan / heart / take / last / versace / away / several / tuesday / spokesman / chief\n",
    "\n",
    "> Topic 6: n't / church / elvis / people / says / music / television / film / life / wright / catholic / while / bishop / little / women / told / tour / fans / father / every\n",
    "\n",
    "> Topic 7: church / service / death / life / against / found / former / bernardin / home / funeral / us / thursday / died / cardinal / court / bishops / west / later / night / made\n",
    "\n",
    "> Topic 8: mother / teresa / order / heart / work / missionaries / nuns / told / sister / charity / hospital / official / poor / successor / calcutta / home / india / last / nun / first\n",
    "\n",
    "> Topic 9: city / germany / people / east / peace / against / prize / art / timor / simpson / award / museum / year / letter / years / told / capital / exhibition / group / culture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapsed Gibbs sampler (faster \"convergence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "... initializing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "... running collapsed gibbs sampler"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:09<00:00, 11.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "We obtained the following topics:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: 1993 / found / part / ashes / christians / earned / mark / bishop / regional / sunday / got / call / takes / conversation / neither / photo / clear / william / raising / paul"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: mother / teresa / heart / calcutta / sen / sunday / order / sister / condition / home / respirator / hospital / nun / doctors / charity / prayers / nuns / tuesday / told / missionaries"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: dresden / million / church / first / state / once / princess / moment / project / interview / crypt / service / become / bishop / baroque / centre / wednesday / 1992 / 1945 / raid"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: charles / church / diana / royal / prince / queen / camilla / palace / family / monday / divorce / parker / bowles / daily / british / marriage / england / years / take / britain"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lda_collapsed_gibbs(K=42, LOOPS=112, α=5., β=.1):\n",
    "    if type(α) == type(1.):\n",
    "        α = np.ones(K)*α\n",
    "    if type(β) == type(1.):\n",
    "        β = np.ones(V)*β\n",
    "        \n",
    "    α0 = np.sum(α)\n",
    "    β0 = np.sum(β)\n",
    "    \n",
    "    md('... initializing')\n",
    "    # initialize sampled variables\n",
    "    z = [np.random.choice(K, len(w[d])) for d in range(D)]\n",
    "    # initialize count tables\n",
    "    c_dk = np.zeros((D, K))\n",
    "    for d in range(D):\n",
    "        c_dk[d,:] = np.bincount(z[d], minlength=K)\n",
    "    c_kv = np.zeros((K, V))\n",
    "    for d in range(D):\n",
    "        for i in range(len(w[d])):\n",
    "            c_kv[z[d][i], w[d][i]] += 1\n",
    "    c_k = np.sum(c_kv, axis=1)\n",
    "    #print(np.sum(c_dk), np.sum(c_kv), np.sum(c_k))\n",
    "    \n",
    "    md('... running collapsed gibbs sampler')\n",
    "    for loop in tqdm(range(LOOPS)):\n",
    "        for d in range(D):\n",
    "            for i in range(len(w[d])):\n",
    "                _wdi = w[d][i]\n",
    "                _zdi = z[d][i]\n",
    "                # remove the point from the counts\n",
    "                c_dk[d, _zdi] -= 1\n",
    "                c_kv[_zdi, _wdi] -= 1\n",
    "                c_k[_zdi] -= 1\n",
    "                # sample the new value\n",
    "                _zdi = draw_cat_prop((α[:] + c_dk[d,:]) * (β[_wdi] + c_kv[:,_wdi]) / (β0 + c_k[:]))\n",
    "                z[d][i] = _zdi\n",
    "                # update the counts\n",
    "                c_dk[d, _zdi] += 1\n",
    "                c_kv[_zdi, _wdi] += 1\n",
    "                c_k[_zdi] += 1\n",
    "                \n",
    "    md('We obtained the following topics:')\n",
    "    φ = c_kv + β[None,:]\n",
    "    #plt.imshow(φ)\n",
    "    #plt.show()\n",
    "    for k in range(K):\n",
    "        txt = 'Topic '+str(k)+': '\n",
    "        words = np.argsort(φ[k,:])[::-1]\n",
    "        txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "        md(txt)\n",
    "\n",
    "lda_collapsed_gibbs(n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Collapsed Gibbs sampler, [timing: 05:25.00]\n",
    "\n",
    "> Topic 0: city / art / great / century / museum / exhibition / tour / first / music / history / cultural / left / time / capital / set / show / while / want / since / culture\n",
    "\n",
    "> Topic 1: political / yeltsin / president / russian / russia / leader / minister / country / party / kremlin / tuesday / moscow / operation / communist / union / power / percent / soviet / heart / say\n",
    "\n",
    "> Topic 2: pope / vatican / paul / world / mass / john / surgery / church / rome / pontiff / trip / sunday / year / since / roman / during / visit / poland / hospital / month\n",
    "\n",
    "> Topic 3: against / film / germany / group / people / east / rights / last / prize / peace / award / letter / christian / human / international / magazine / french / timor / spokesman / country\n",
    "\n",
    "> Topic 4: u.s / harriman / clinton / elvis / churchill / paris / president / france / ambassador / died / late / american / first / husband / age / winston / war / state / born / death\n",
    "\n",
    "> Topic 5: police / life / service / family / national / simpson / miami / versace / first / funeral / cunanan / people / men / church / home / night / held / wednesday / say / star\n",
    "\n",
    "> Topic 6: charles / prince / family / royal / king / diana / public / queen / church / bowles / parker / camilla / marriage / newspaper / princess / married / throne / british / britain / years\n",
    "\n",
    "> Topic 7: years / million / government / world / people / former / british / three / war / west / year / town / law / four / south / went / john / sale / women / letters\n",
    "\n",
    "> Topic 8: church / catholic / n't / years / told / bishop / cardinal / bernardin / last / died / father / life / son / michael / wright / romania / former / during / know / death\n",
    "\n",
    "> Topic 9: mother / teresa / order / heart / work / hospital / charity / nuns / sister / home / calcutta / missionaries / roman / world / poor / successor / last / doctors / nun / peace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Using the lda library\n",
    "This library implements a Collapsed Gibbs sampler but with cython instead of python loops (and with a slightly better sparse representation).\n",
    "It is much faster (due to cython) compared to our above implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 395\n",
      "INFO:lda:vocab_size: 4258\n",
      "INFO:lda:n_words: 84010\n",
      "INFO:lda:n_topics: 4\n",
      "INFO:lda:n_iter: 112\n",
      "INFO:lda:<0> log likelihood: -802269\n",
      "INFO:lda:<100> log likelihood: -683441\n",
      "INFO:lda:<111> log likelihood: -683110\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: charles / king / british / harriman / u.s / prince / church / first / clinton / died / family / elvis / royal / diana / churchill / years / public / son / queen / marriage"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: city / people / film / police / against / life / germany / years / church / n't / made / show / french / home / director / international / music / national / simpson / year"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: pope / mother / teresa / catholic / church / vatican / order / world / hospital / roman / john / told / doctors / sunday / heart / surgery / last / peace / paul / mass"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: church / president / government / political / yeltsin / country / last / leader / russian / minister / former / war / under / russia / million / three / people / union / party / says"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = lda_lib.LDA(n_topics, 112, 5., .1, refresh=100)\n",
    "L.fit(nW)\n",
    "\n",
    "φ = L.components_\n",
    "for k in range(n_topics):\n",
    "    txt = 'Topic '+str(k)+': '\n",
    "    words = np.argsort(φ[k,:])[::-1]\n",
    "    txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "    md(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: `lda` library (Collapsed Gibbs sampler) [timing: 00:01.66]\n",
    "\n",
    "> Topic 0: yeltsin / president / russian / russia / bernardin / last / union / kremlin / moscow / orthodox / operation / communist / soviet / take / say / power / country / political / church / under\n",
    "\n",
    "> Topic 1: mother / teresa / order / heart / work / hospital / told / charity / nuns / official / calcutta / missionaries / sister / home / last / election / world / poor / senior / successor\n",
    "\n",
    "> Topic 2: harriman / u.s / clinton / war / churchill / paris / died / president / france / british / ambassador / american / first / became / winston / campaign / minister / state / party / husband\n",
    "\n",
    "> Topic 3: city / million / century / years / music / used / since / first / art / made / exhibition / year / museum / off / culture / history / churches / cultural / capital / including\n",
    "\n",
    "> Topic 4: pope / vatican / church / paul / john / mass / sunday / rome / world / during / surgery / roman / pontiff / trip / day / since / hospital / visit / poland / health\n",
    "\n",
    "> Topic 5: church / service / police / south / funeral / family / simpson / miami / versace / found / cunanan / national / held / home / death / wednesday / friday / night / law / thursday\n",
    "\n",
    "> Topic 6: elvis / film / germany / against / french / german / group / fans / west / letter / people / called / says / every / king / magazine / festival / france / concert / made\n",
    "\n",
    "> Topic 7: charles / prince / king / public / royal / diana / family / queen / church / british / bowles / parker / camilla / britain / marriage / princess / throne / years / married / love\n",
    "\n",
    "> Topic 8: n't / life / years / told / people / own / very / time / church / television / never / first / world / say / women / catholic / show / bishop / year / later\n",
    "\n",
    "> Topic 9: government / political / former / church / leader / minister / east / years / last / country / peace / prize / people / catholic / rights / party / ceremony / award / president / united\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we show how to make ours faster\n",
    "- with numba (we have to jump through a few hoops, but very good gain) (3.8s)\n",
    "- then with an improved sparse representation (not much gain as we still loop in pure python) (5min 20s)\n",
    "- then with both (even better gain) (2.55s)\n",
    "- reminder: cython impl from the library (1.5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapsed Gibbs sampler, with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "... initializing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "... running collapsed gibbs sampler"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:00<00:00, 133.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "We obtained the following topics:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: prince / palace / daily / royal / changes / reforms / committee / heir-to-the-throne / head / princess / ending / main / moves / monarchy / monarch / throne / changing / 1992 / marriages / supreme"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: mother / teresa / heart / calcutta / sen / order / sunday / sister / condition / home / respirator / told / hospital / doctors / prayers / tuesday / nun / charity / nuns / missionaries"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: charles / church / diana / queen / camilla / british / divorce / against / bowles / parker / britain / years / monday / million / take / buckingham / marriage / since / family / newspaper"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: dresden / next / service / centre / project / famous / spent / officials / crypt / moment / ashes / regional / baroque / news / again / divorced / inauguration / far / 1945 / ceremony"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lda_collapsed_gibbs_numba(K=42, LOOPS=112, α=5., β=.1, ___globalW=w):\n",
    "    if type(α) == type(1.):\n",
    "        α = np.ones(K)*α\n",
    "    if type(β) == type(1.):\n",
    "        β = np.ones(V)*β\n",
    "        \n",
    "    α0 = np.sum(α)\n",
    "    β0 = np.sum(β)\n",
    "    \n",
    "    md('... initializing')\n",
    "    # Hoop 1: use special lists\n",
    "    w = numba.typed.List()\n",
    "    for _wd in ___globalW:\n",
    "        w.append(numba.typed.List(_wd))\n",
    "    \n",
    "    # initialize sampled variables\n",
    "    z = [np.random.choice(K, len(w[d])) for d in range(D)]\n",
    "    z = numba.typed.List(z)\n",
    "        \n",
    "    # initialize count tables\n",
    "    c_dk = np.zeros((D, K))\n",
    "    for d in range(D):\n",
    "        c_dk[d,:] = np.bincount(z[d], minlength=K)\n",
    "    c_kv = np.zeros((K, V))\n",
    "    for d in range(D):\n",
    "        for i in range(len(w[d])):\n",
    "            c_kv[z[d][i], w[d][i]] += 1\n",
    "    c_k = np.sum(c_kv, axis=1)\n",
    "    #print(np.sum(c_dk), np.sum(c_kv), np.sum(c_k))\n",
    "    \n",
    "    md('... running collapsed gibbs sampler')\n",
    "    \n",
    "    # based on https://github.com/numba/numba/issues/2539#issuecomment-507306369\n",
    "    @numba.jit(nopython=True)\n",
    "    def draw_cat_prop(p):\n",
    "        p /= np.sum(p)\n",
    "        # hoop 2: work around the missing p parameter to random.choice\n",
    "        return np.searchsorted(np.cumsum(p), np.random.random(), side=\"right\")\n",
    "\n",
    "    @numba.jit(nopython=True)\n",
    "    def loopit(c_dk, c_kv, c_k, w, z):\n",
    "        for d in range(D):\n",
    "            _wd = w[d]\n",
    "            for i in range(len(_wd)):\n",
    "                _wdi = _wd[i]\n",
    "                _zdi = z[d][i]\n",
    "                # remove the point from the counts\n",
    "                c_dk[d, _zdi] -= 1\n",
    "                c_kv[_zdi, _wdi] -= 1\n",
    "                c_k[_zdi] -= 1\n",
    "                # sample the new value\n",
    "                _zdi = draw_cat_prop((α[:] + c_dk[d,:]) * (β[_wdi] + c_kv[:,_wdi]) / (β0 + c_k[:]))\n",
    "                z[d][i] = _zdi\n",
    "                # update the counts\n",
    "                c_dk[d, _zdi] += 1\n",
    "                c_kv[_zdi, _wdi] += 1\n",
    "                c_k[_zdi] += 1\n",
    "\n",
    "    \n",
    "    for loop in tqdm(range(LOOPS)):\n",
    "        loopit(c_dk, c_kv, c_k, w, z)\n",
    "                \n",
    "    md('We obtained the following topics:')\n",
    "    φ = c_kv + β[None,:]\n",
    "    #plt.imshow(φ)\n",
    "    #plt.show()\n",
    "    for k in range(K):\n",
    "        txt = 'Topic '+str(k)+': '\n",
    "        words = np.argsort(φ[k,:])[::-1]\n",
    "        txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "        md(txt)\n",
    "    \n",
    "lda_collapsed_gibbs_numba(n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Numba for Collapsed Gibbs sampler [timing: 00:03.48]\n",
    "\n",
    "> Topic 0: city / germany / german / christian / million / art / century / since / history / set / letter / exhibition / museum / year / nazi / capital / against / jews / international / government\n",
    "\n",
    "> Topic 1: charles / prince / king / public / diana / royal / family / queen / parker / bowles / britain / british / camilla / marriage / church / years / princess / throne / married / newspaper\n",
    "\n",
    "> Topic 2: mother / teresa / order / work / heart / charity / hospital / nuns / sister / told / calcutta / home / missionaries / world / successor / senior / roman / poor / last / official\n",
    "\n",
    "> Topic 3: church / n't / say / very / television / while / bishop / years / world / women / father / time / long / go / never / three / held / come / wright / catholic\n",
    "\n",
    "> Topic 4: yeltsin / political / president / russian / government / russia / minister / michael / country / kremlin / moscow / power / communist / soviet / leader / romania / party / take / operation / orthodox\n",
    "\n",
    "> Topic 5: church / years / during / last / bernardin / life / against / catholic / john / people / death / national / french / cardinal / former / died / court / france / time / south\n",
    "\n",
    "> Topic 6: elvis / film / life / people / music / simpson / first / fans / won / king / years / west / every / festival / tour / best / concert / stars / used / world\n",
    "\n",
    "> Topic 7: u.s / harriman / clinton / churchill / war / paris / british / first / president / ambassador / france / american / late / party / monday / winston / former / minister / husband / state\n",
    "\n",
    "> Topic 8: police / people / service / funeral / told / home / family / east / ceremony / miami / thursday / versace / cunanan / peace / church / spokesman / night / prize / city / friday\n",
    "\n",
    "> Topic 9: pope / vatican / paul / during / church / surgery / john / mass / since / roman / trip / rome / pontiff / hospital / world / visit / doctors / sunday / health / poland\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better representation for Collapsed Gibbs sampler (same speed, as it is still pure python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "... initializing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "... running collapsed gibbs sampler"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:09<00:00, 11.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "We obtained the following topics:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: mother / teresa / heart / calcutta / sunday / sen / order / condition / sister / home / respirator / hospital / doctors / nun / nuns / tuesday / charity / told / prayers / fever"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: charles / diana / royal / queen / prince / palace / camilla / take / church / family / divorce / monday / parker / british / daily / britain / bowles / spokeswoman / buckingham / marriage"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: later / strategic / telegraph / difficult / taken / latest / member / john / inspired / 20 / working / late / married / huge / woman / bar / hill / end / responded / wife"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: church / dresden / members / bishop / million / once / service / state / years / found / raid / days / 1945 / ashes / tabloid / ceremony / centre / britons / marks / unable"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lda_collapsed_gibbs_goodrepr(K=42, LOOPS=112, α=5., β=.1):\n",
    "    if type(α) == type(1.):\n",
    "        α = np.ones(K)*α\n",
    "    if type(β) == type(1.):\n",
    "        β = np.ones(V)*β\n",
    "        \n",
    "    α0 = np.sum(α)\n",
    "    β0 = np.sum(β)\n",
    "    \n",
    "    md('... initializing')\n",
    "    allw = np.array([_wdi for _wd in w for _wdi in _wd])\n",
    "    alld = np.array([d for d in range(D) for i in range(len(w[d]))])\n",
    "    S = alld.shape[0] # total size across all the (considered) documents\n",
    "    # initialize sampled variables\n",
    "    z = np.random.choice(K, S)\n",
    "    # initialize count tables\n",
    "    c_dk = np.zeros((D, K))\n",
    "    for d in range(D):\n",
    "        c_dk[d,:] = np.bincount(z[alld==d], minlength=K)\n",
    "    c_kv = np.zeros((K, V))\n",
    "    for di in range(S):\n",
    "        c_kv[z[di], allw[di]] += 1\n",
    "    c_k = np.sum(c_kv, axis=1)\n",
    "    #print(np.sum(c_dk), np.sum(c_kv), np.sum(c_k))\n",
    "    \n",
    "    md('... running collapsed gibbs sampler')\n",
    "    for loop in tqdm(range(LOOPS)):\n",
    "        for di in range(S):\n",
    "            d = alld[di]\n",
    "            _wdi = allw[di]\n",
    "            _zdi = z[di]\n",
    "            # remove the point from the counts\n",
    "            c_dk[d, _zdi] -= 1\n",
    "            c_kv[_zdi, _wdi] -= 1\n",
    "            c_k[_zdi] -= 1\n",
    "            # sample the new value\n",
    "            _zdi = draw_cat_prop((α[:] + c_dk[d,:]) * (β[_wdi] + c_kv[:,_wdi]) / (β0 + c_k[:]))\n",
    "            z[di] = _zdi\n",
    "            # update the counts\n",
    "            c_dk[d, _zdi] += 1\n",
    "            c_kv[_zdi, _wdi] += 1\n",
    "            c_k[_zdi] += 1\n",
    "                \n",
    "    md('We obtained the following topics:')\n",
    "    φ = c_kv + β[None,:]\n",
    "    #plt.imshow(φ)\n",
    "    #plt.show()\n",
    "    for k in range(K):\n",
    "        txt = 'Topic '+str(k)+': '\n",
    "        words = np.argsort(φ[k,:])[::-1]\n",
    "        txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "        md(txt)\n",
    "    \n",
    "    \n",
    "lda_collapsed_gibbs_goodrepr(n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Better representation for Collapsed Gibbs sampler [timing: 05:33.00]\n",
    "\n",
    "> Topic 0: years / city / million / world / set / simpson / time / century / art / museum / used / during / since / own / part / once / churches / first / music / great\n",
    "\n",
    "> Topic 1: political / yeltsin / president / russian / russia / leader / country / last / union / kremlin / state / moscow / minister / percent / under / soviet / government / party / communist / power\n",
    "\n",
    "> Topic 2: mother / teresa / order / heart / work / charity / official / hospital / told / nuns / world / home / calcutta / missionaries / sister / peace / last / poor / election / head\n",
    "\n",
    "> Topic 3: church / died / service / people / south / funeral / former / local / government / ceremony / during / last / michael / first / visit / friday / romania / country / wednesday / white\n",
    "\n",
    "> Topic 4: u.s / harriman / clinton / president / war / churchill / american / paris / british / ambassador / france / became / minister / home / party / winston / very / husband / state / former\n",
    "\n",
    "> Topic 5: against / film / life / french / bernardin / year / years / rights / france / court / death / cardinal / west / festival / chicago / cancer / found / magazine / national / conservative\n",
    "\n",
    "> Topic 6: charles / prince / diana / royal / family / king / public / queen / years / british / parker / bowles / camilla / marriage / britain / princess / throne / married / church / england\n",
    "\n",
    "> Topic 7: church / n't / told / people / show / very / catholic / say / television / bishop / know / life / news / think / time / come / wright / want / came / love\n",
    "\n",
    "> Topic 8: pope / vatican / john / paul / church / mass / roman / surgery / world / sunday / catholic / rome / trip / pontiff / hospital / three / left / day / since / poland\n",
    "\n",
    "> Topic 9: elvis / police / germany / city / german / called / international / fans / miami / versace / cunanan / thursday / death / off / jews / nazi / king / letter / concert / states\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba+Representation for Collapsed Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "... initializing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "... running collapsed gibbs sampler"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:00<00:00, 253.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "We obtained the following topics:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: mother / teresa / heart / calcutta / sunday / sen / order / sister / condition / home / hospital / respirator / nun / doctors / told / tuesday / charity / prayers / nuns / fever"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: church / dresden / million / love / part / service / main / high / temperature / ceremony / baroque / far / inauguration / centre / project / john / ashes / allowed / 1945 / crypt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: charles / diana / church / queen / royal / prince / camilla / palace / bowles / parker / take / british / family / divorce / britain / england / buckingham / daily / spokeswoman / marriage"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: monday / committee / member / members / marks / cannot / agreed / very / might / showed / pay / strategic / minister / 1949 / marry / governor / head / century / moment / raise"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lda_collapsed_gibbs_goodrepr_numba(K=42, LOOPS=112, α=5., β=.1):\n",
    "    if type(α) == type(1.):\n",
    "        α = np.ones(K)*α\n",
    "    if type(β) == type(1.):\n",
    "        β = np.ones(V)*β\n",
    "        \n",
    "    α0 = np.sum(α)\n",
    "    β0 = np.sum(β)\n",
    "    \n",
    "    md('... initializing')\n",
    "    allw = np.array([_wdi for _wd in w for _wdi in _wd])\n",
    "    alld = np.array([d for d in range(D) for i in range(len(w[d]))])\n",
    "    S = alld.shape[0] # total size across all the (considered) documents\n",
    "    # initialize sampled variables\n",
    "    z = np.random.choice(K, S)\n",
    "    # initialize count tables\n",
    "    c_dk = np.zeros((D, K))\n",
    "    for d in range(D):\n",
    "        c_dk[d,:] = np.bincount(z[alld==d], minlength=K)\n",
    "    c_kv = np.zeros((K, V))\n",
    "    for di in range(S):\n",
    "        c_kv[z[di], allw[di]] += 1\n",
    "    c_k = np.sum(c_kv, axis=1)\n",
    "    #print(np.sum(c_dk), np.sum(c_kv), np.sum(c_k))\n",
    "    \n",
    "    md('... running collapsed gibbs sampler')\n",
    "    # based on https://github.com/numba/numba/issues/2539#issuecomment-507306369\n",
    "    @numba.jit(nopython=True)\n",
    "    def draw_cat_prop(p):\n",
    "        p /= np.sum(p)\n",
    "        # hoop 2: work around the missing p parameter to random.choice\n",
    "        return np.searchsorted(np.cumsum(p), np.random.random(), side=\"right\")\n",
    "\n",
    "    @numba.jit(nopython=True)\n",
    "    def loopit(c_dk, c_kv, c_k, alld, allw, z):\n",
    "        for di in range(S):\n",
    "            d = alld[di]\n",
    "            _wdi = allw[di]\n",
    "            _zdi = z[di]\n",
    "            # remove the point from the counts\n",
    "            c_dk[d, _zdi] -= 1\n",
    "            c_kv[_zdi, _wdi] -= 1\n",
    "            c_k[_zdi] -= 1\n",
    "            # sample the new value\n",
    "            _zdi = draw_cat_prop((α[:] + c_dk[d,:]) * (β[_wdi] + c_kv[:,_wdi]) / (β0 + c_k[:]))\n",
    "            z[di] = _zdi\n",
    "            # update the counts\n",
    "            c_dk[d, _zdi] += 1\n",
    "            c_kv[_zdi, _wdi] += 1\n",
    "            c_k[_zdi] += 1\n",
    "\n",
    "    #loopit(c_dk, c_kv, c_k, alld, allw, z, LOOPS)\n",
    "    for loop in tqdm(range(LOOPS)):\n",
    "        loopit(c_dk, c_kv, c_k, alld, allw, z)\n",
    "                \n",
    "    md('We obtained the following topics:')\n",
    "    φ = c_kv + β[None,:]\n",
    "    #plt.imshow(φ)\n",
    "    #plt.show()\n",
    "    for k in range(K):\n",
    "        txt = 'Topic '+str(k)+': '\n",
    "        words = np.argsort(φ[k,:])[::-1]\n",
    "        txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "        md(txt)\n",
    "    \n",
    "    \n",
    "lda_collapsed_gibbs_goodrepr_numba(n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Numba+representation for Collapsed Gibbs sampler [timing: 00:02.40]\n",
    "\n",
    "> Topic 0: political / city / russian / country / leader / state / minister / union / president / russia / since / moscow / part / capital / year / christian / time / power / soviet / percent\n",
    "\n",
    "> Topic 1: church / catholic / told / bishop / president / bernardin / people / peace / ceremony / cardinal / east / life / prize / former / death / during / wright / last / years / roman\n",
    "\n",
    "> Topic 2: pope / vatican / yeltsin / surgery / operation / paul / mass / church / health / doctors / rome / hospital / during / pontiff / trip / world / since / last / tuesday / sunday\n",
    "\n",
    "> Topic 3: charles / harriman / prince / u.s / clinton / british / royal / diana / churchill / queen / marriage / public / parker / bowles / camilla / family / ambassador / princess / paris / england\n",
    "\n",
    "> Topic 4: war / first / last / million / government / century / people / years / michael / church / visit / exhibition / museum / romania / place / put / small / art / five / three\n",
    "\n",
    "> Topic 5: against / film / germany / french / german / france / group / west / letter / country / festival / book / people / nazi / american / director / says / magazine / paris / rights\n",
    "\n",
    "> Topic 6: n't / world / television / year / church / people / until / while / time / never / day / several / few / own / south / think / among / off / end / days\n",
    "\n",
    "> Topic 7: mother / teresa / order / heart / charity / hospital / work / election / nuns / calcutta / sister / missionaries / told / official / religious / home / poor / head / senior / nun\n",
    "\n",
    "> Topic 8: years / elvis / first / life / king / death / simpson / died / fans / father / left / every / world / women / year / black / three / music / children / popular\n",
    "\n",
    "> Topic 9: family / police / service / church / funeral / former / home / thursday / miami / versace / very / cunanan / york / died / night / city / us / told / kennedy / men\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we try with some Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapsed Variational Inference, from intuitive (wrong?) derivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "... initializing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "... running collapsed variational inference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:12<00:00,  9.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "We obtained the following topics:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4258)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: mother / teresa / heart / calcutta / sunday / sen / order / sister / condition / home / doctors / nun / hospital / told / charity / prayers / nuns / tuesday / missionaries / fever"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: charles / church / diana / queen / prince / royal / years / camilla / palace / monday / against / take / bowles / parker / divorce / family / daily / dresden / million / britain"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: respirator / people / saint / house / world / thousands / pray / admitted / roman / life / birthday / dr / long / days / irregular / several / blessed / hope / tomorrow / problems"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: british / year / praying / n't / age / nada / strength / buckingham / under / spokeswoman / reporters / marks / reforms / committee / changes / showing / public / might / newspaper / help"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lda_collapsed_vi(K=42, LOOPS=112, α=5., β=.1):\n",
    "    if type(α) == type(1.):\n",
    "        α = np.ones(K)*α\n",
    "    if type(β) == type(1.):\n",
    "        β = np.ones(V)*β\n",
    "        \n",
    "    α0 = np.sum(α)\n",
    "    β0 = np.sum(β)\n",
    "    \n",
    "    md('... initializing')\n",
    "    # initialize variational parameters\n",
    "    ν = [np.random.dirichlet(np.ones(K), len(w[d])) for d in range(D)]\n",
    "\n",
    "    \n",
    "    def expdigamma_big(x):\n",
    "        x = x - 0.5\n",
    "        return x + 1/(24*x) - 37/(5760*x**3)\n",
    "\n",
    "    def expdigamma(x):\n",
    "        return expdigamma_big(x+1) / np.exp(1/x)\n",
    "        #return expdigamma_big(x+2) / np.exp(1/x + 1/(x+1))\n",
    "    \n",
    "    md('... running collapsed variational inference')\n",
    "    for loop in tqdm(range(LOOPS)):\n",
    "        νnew = []\n",
    "        # precompute what can be\n",
    "        sumν_kv = np.zeros((K, V))\n",
    "        for d in range(D):\n",
    "            _wd = w[d]\n",
    "            Nd = len(_wd)\n",
    "            νd = ν[d] # (Nd, K)\n",
    "            for i in range(Nd):\n",
    "                _wdi = _wd[i]\n",
    "                sumν_kv[:,_wdi] += νd[i, :]\n",
    "        sumν_k = np.sum(sumν_kv, axis=1)\n",
    "        # compute the actual new ν\n",
    "        for d in range(D):\n",
    "            _wd = w[d]\n",
    "            Nd = len(_wd)\n",
    "            νd = ν[d]                  # (Nd, K)\n",
    "            νnewd = np.zeros((Nd, K))\n",
    "            νnew.append(νnewd)\n",
    "            ψ0 = digamma(α0 + Nd - 1)\n",
    "            αsumνd_k = α + np.sum(νd, axis=0)\n",
    "            for i in range(Nd):\n",
    "                _wdi = _wd[i]\n",
    "                p = ( expdigamma(β[_wdi] + sumν_kv[:,_wdi] - νd[i,:])\n",
    "                    / expdigamma(β0 + sumν_k - νd[i,:])\n",
    "                    * expdigamma(αsumνd_k - νd[i,:])\n",
    "                    #/ expdigamma(α0 + Nd - 1)\n",
    "                )\n",
    "                #p = digamma(β[_wdi] + sumν_kv[:,_wdi] - νd[i,:]) - digamma(β0 + sumν_k - νd[i,:]) + digamma(αsumνd_k - νd[i,:]) - ψ0\n",
    "                #p = np.exp(p)\n",
    "                p = p / np.sum(p)\n",
    "                νnewd[i,:] = p\n",
    "        ν = νnew\n",
    "                \n",
    "    md('We obtained the following topics:')\n",
    "    φ = sumν_kv + β[None,:]\n",
    "    print(φ.shape)\n",
    "    #plt.imshow(φ)\n",
    "    #plt.show()\n",
    "    for k in range(K):\n",
    "        txt = 'Topic '+str(k)+': '\n",
    "        words = np.argsort(φ[k,:])[::-1]\n",
    "        txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "        md(txt)\n",
    "    \n",
    "lda_collapsed_vi(n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Hacky Variational Inference [timing: 00:07.26]\n",
    "\n",
    "> Topic 0: city / germany / german / century / art / war / capital / west / union / exhibition / museum / soviet / letter / churches / nazi / says / international / great / jews / world\n",
    "\n",
    "> Topic 1: people / political / east / peace / rights / group / went / prize / country / against / award / economic / last / saturday / president / told / campaign / letters / timor / human\n",
    "\n",
    "> Topic 2: charles / king / prince / elvis / diana / royal / family / queen / public / parker / bowles / camilla / marriage / princess / married / throne / music / years / love / first\n",
    "\n",
    "> Topic 3: church / n't / film / people / against / south / years / women / catholic / french / life / know / won / never / bishop / wright / father / very / made / few\n",
    "\n",
    "> Topic 4: yeltsin / president / doctors / operation / russian / last / since / surgery / leader / hospital / tuesday / russia / kremlin / news / month / monday / three / heart / minister / statement\n",
    "\n",
    "> Topic 5: mother / teresa / order / heart / work / charity / nuns / sister / home / calcutta / told / missionaries / head / hospital / official / election / poor / india / last / members\n",
    "\n",
    "> Topic 6: former / million / party / year / years / leader / time / political / simpson / made / past / television / months / country / three / kennedy / parliament / sale / court / vote\n",
    "\n",
    "> Topic 7: church / government / british / ceremony / last / minister / michael / former / law / during / public / years / officials / newspaper / romania / become / visit / while / opinion / friday\n",
    "\n",
    "> Topic 8: harriman / u.s / clinton / churchill / paris / france / died / president / american / ambassador / british / police / war / late / service / home / funeral / death / became / family\n",
    "\n",
    "> Topic 9: pope / church / vatican / john / world / during / catholic / paul / roman / mass / cardinal / left / sunday / bernardin / life / day / rome / years / trip / pontiff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapsed Variational Inference, from intuitive (wrong?) derivations + repr+numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "... initializing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "... running collapsed variational inference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:02<00:00, 46.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "We obtained the following topics:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4258)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Topic 0: charles / church / diana / queen / prince / royal / years / camilla / palace / take / parker / bowles / divorce / british / daily / britain / dresden / against / marriage / england"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 1: mother / teresa / heart / calcutta / sunday / sen / home / respirator / nun / hospital / doctors / nuns / tuesday / fever / saint / people / catholic / nursing / house / world"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 2: family / special / million / age / princess / reporters / tomorrow / changes / reforms / wales / head / first / bishop / services / help / died / anything / albanian-born / evening / state"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Topic 3: order / sister / condition / told / prayers / charity / missionaries / woodlands / poor / peace / day / remained / vomiting / senior / nobel / slightly / dr / known / god / including"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lda_collapsed_vi_numba(K=42, LOOPS=112, α=5., β=.1):\n",
    "    if type(α) == type(1.):\n",
    "        α = np.ones(K)*α\n",
    "    if type(β) == type(1.):\n",
    "        β = np.ones(V)*β\n",
    "        \n",
    "    α0 = np.sum(α)\n",
    "    β0 = np.sum(β)\n",
    "    \n",
    "    md('... initializing')\n",
    "    allw = np.array([_wdi for _wd in w for _wdi in _wd])\n",
    "    alld = np.array([d for d in range(D) for i in range(len(w[d]))])\n",
    "    S = alld.shape[0] # total size across all the (considered) documents\n",
    "\n",
    "    # initialize variational parameters\n",
    "    ν = np.random.dirichlet(np.ones(K), S)\n",
    "\n",
    "    @numba.jit(nopython=True)\n",
    "    def expdigamma_big(x):\n",
    "        x = x - 0.5\n",
    "        return x + 1/(24*x) #- 37/(5760*x**3)\n",
    "\n",
    "    @numba.jit(nopython=True)\n",
    "    def expdigamma(x):\n",
    "        return expdigamma_big(x+1) / np.exp(1/x)\n",
    "        return expdigamma_big(x+2) / np.exp(1/x + 1/(x+1))\n",
    "    \n",
    "    @numba.jit(nopython=True)\n",
    "    def loopit(ν, alld, allw):\n",
    "        νnew = np.zeros(ν.shape) # (S, K)\n",
    "        # precompute what can be\n",
    "        sumν_kv = np.zeros((K, V))\n",
    "        sumν_dk = np.zeros((D, K))\n",
    "        N = np.zeros(D)\n",
    "        for di in range(S):\n",
    "            d = alld[di]\n",
    "            N[d] += 1\n",
    "            _wdi = allw[di]\n",
    "            sumν_kv[:,_wdi] += ν[di, :]\n",
    "            sumν_dk[d,:] += ν[di, :]\n",
    "\n",
    "        sumν_k = np.sum(sumν_kv, axis=1)\n",
    "        \n",
    "        for di in range(S):\n",
    "            d = alld[di]\n",
    "            Nd = N[d]\n",
    "            _wdi = allw[di]\n",
    "            p = ( expdigamma(β[_wdi] + sumν_kv[:,_wdi] - ν[di,:])\n",
    "                / expdigamma(β0 + sumν_k - ν[di,:])\n",
    "                * expdigamma(α + sumν_dk[d, :] - ν[di,:])\n",
    "                #/ expdigamma(α0 + Nd - 1)\n",
    "                )\n",
    "            #             _zdi = draw_cat_prop(   (α[:] + c_dk[d,:]) * (β[_wdi] + c_kv[:,_wdi]) / (β0 + c_k[:]))\n",
    "            #p = np.exp(p)\n",
    "            p = p / np.sum(p)\n",
    "            νnew[di,:] = p\n",
    "            \n",
    "        return νnew, sumν_kv\n",
    "\n",
    "\n",
    "    md('... running collapsed variational inference')\n",
    "    for loop in tqdm(range(LOOPS)):\n",
    "        ν, sumν_kv = loopit(ν, alld, allw)\n",
    "                \n",
    "    md('We obtained the following topics:')\n",
    "    φ = sumν_kv + β[None,:]\n",
    "    print(φ.shape)\n",
    "    #plt.imshow(φ)\n",
    "    #plt.show()\n",
    "    for k in range(K):\n",
    "        txt = 'Topic '+str(k)+': '\n",
    "        words = np.argsort(φ[k,:])[::-1]\n",
    "        txt += ' / '.join([v_to_text[v] for v in words[:20]])\n",
    "        md(txt)\n",
    "    \n",
    "lda_collapsed_vi_numba(n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Numba+representation for Hacky Variational Inference [timing: 00:18.30]\n",
    "\n",
    "> Topic 0: church / police / service / family / south / told / father / died / funeral / friday / us / national / home / miami / thursday / versace / went / body / held / cunanan\n",
    "\n",
    "> Topic 1: u.s / harriman / british / prince / clinton / royal / churchill / party / war / president / minister / britain / paris / american / ambassador / prime / son / france / died / became\n",
    "\n",
    "> Topic 2: charles / public / diana / queen / church / bowles / parker / camilla / newspaper / love / media / simpson / family / couple / marriage / divorce / woman / together / years / princess\n",
    "\n",
    "> Topic 3: pope / church / vatican / john / catholic / paul / mass / during / cardinal / east / roman / surgery / world / bernardin / rome / pontiff / peace / trip / years / left\n",
    "\n",
    "> Topic 4: mother / teresa / order / hospital / heart / doctors / work / charity / last / election / told / nuns / sister / official / calcutta / tuesday / missionaries / sunday / successor / since\n",
    "\n",
    "> Topic 5: church / leader / people / years / three / time / say / last / including / reports / week / exhibition / saying / end / himself / former / go / under / around / although\n",
    "\n",
    "> Topic 6: elvis / first / people / life / saturday / n't / told / fans / king / death / condition / age / every / mark / music / live / politics / called / own / lives\n",
    "\n",
    "> Topic 7: president / yeltsin / political / russian / russia / country / michael / operation / kremlin / government / moscow / take / orthodox / power / communist / union / return / economic / museum / europe\n",
    "\n",
    "> Topic 8: against / film / group / germany / french / people / france / show / director / rights / award / west / festival / art / made / country / german / international / magazine / conservative\n",
    "\n",
    "> Topic 9: city / years / million / year / people / king / great / while / government / world / until / capital / century / old / southern / tour / past / set / made / air\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential of digamma/ψ/F approximation (checking its quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expdigamma_big(x):\n",
    "    x = x - 0.5\n",
    "    return x + 1/(24*x) - 37/(5760*x**3)\n",
    "\n",
    "def expdigamma(x):\n",
    "    #return expdigamma_big(x+1) / np.exp(1/x)\n",
    "    return expdigamma_big(x+2) / np.exp(1/x + 1/(x+1))\n",
    "    sub = 1\n",
    "    while x <= 2:\n",
    "        sub *= np.exp(1/x)\n",
    "        x = x+1\n",
    "    return expdigamma_big(x) / sub\n",
    "\n",
    "x = np.linspace(.1, 10, 300)\n",
    "ytrue = np.exp(digamma(x))\n",
    "yapprox = np.array([expdigamma(x) for x in x])\n",
    "\n",
    "###plt.plot(x, ytrue, label=\"true\")\n",
    "###plt.plot(x, expdigamma(x), label=\"approx\")\n",
    "\n",
    "#plt.plot(x, (ytrue - yapprox) / (ytrue + yapprox) * 2, label=\"rel \")\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
